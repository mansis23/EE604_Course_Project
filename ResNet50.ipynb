{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Y5IDFjXg0X"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths for the zip file and its extraction location\n",
        "# Update this path based on your file location in Colab\n",
        "zip_path = '/content/faces_224.zip'  # Path to the uploaded zip file\n",
        "unzip_path = '/content'   # Path where files will be unzipped\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_path)\n",
        "\n",
        "# Update the image path\n",
        "image_path = unzip_path"
      ],
      "metadata": {
        "id": "dBMqF3YaY-hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_resnet_model(input_shape=(224, 224, 3)):\n",
        "    base_model = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_data_augmentation():\n",
        "    return ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range=[0.8, 1.2],   # Added brightness adjustment\n",
        "        zoom_range=0.2,                # Added zoom\n",
        "        preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
        "    )\n",
        "\n",
        "\n",
        "def train_resnet_model(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs=20):\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                        validation_data=val_generator, validation_steps=validation_steps,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def fine_tune_resnet_model(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs=10):\n",
        "    base_model = model.layers[0]  # Get the base model (ResNet50)\n",
        "    base_model.trainable = True   # Unfreeze the base model for fine-tuning\n",
        "\n",
        "    # Freeze all layers except the last few (fine-tune only these layers)\n",
        "    for layer in base_model.layers[:-10]:  # Adjust the number of layers as needed\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                        validation_data=val_generator, validation_steps=validation_steps,\n",
        "                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def retrieve_generator(set_name, image_path, target_size=(224, 224), batch_size=32):\n",
        "    while True:\n",
        "        for start in range(0, len(set_name), batch_size):\n",
        "            images, labels = [], []\n",
        "            end = min(start + batch_size, len(set_name))\n",
        "            batch_set = set_name[start:end]\n",
        "\n",
        "            for img, imclass in zip(batch_set['videoname'], batch_set['label']):\n",
        "                img_path = os.path.join(image_path, img[:-4] + '.jpg')\n",
        "                image = cv2.imread(img_path)\n",
        "\n",
        "                if image is not None:\n",
        "                    image = cv2.resize(image, target_size)\n",
        "                    images.append(image)\n",
        "                    labels.append(1 if imclass == 'FAKE' else 0)\n",
        "                else:\n",
        "                    print(f\"Warning: Image not found or cannot be read - {img_path}\")\n",
        "\n",
        "            # Yield batch\n",
        "            yield np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "HcXbmsaQZD55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Define dataset paths (using your existing paths)\n",
        "    metadata_path = r\"/content/metadata.csv\"\n",
        "    image_path = r\"/content/faces_224\"\n",
        "\n",
        "    # Load metadata\n",
        "    print(\"Loading metadata...\")\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    print(\"Metadata loaded.\")\n",
        "\n",
        "    # Sample and split data\n",
        "    print(\"Splitting dataset...\")\n",
        "    real_df = df[df[\"label\"] == \"REAL\"]\n",
        "    fake_df = df[df[\"label\"] == \"FAKE\"]\n",
        "    sample_size = 10000\n",
        "    real_df = real_df.sample(sample_size, random_state=42)\n",
        "    fake_df = fake_df.sample(sample_size, random_state=42)\n",
        "    sample_meta = pd.concat([real_df, fake_df])\n",
        "\n",
        "    Train_set, Test_set = train_test_split(sample_meta, test_size=0.2, random_state=42, stratify=sample_meta['label'])\n",
        "    Train_set, Val_set = train_test_split(Train_set, test_size=0.3, random_state=42, stratify=Train_set['label'])\n",
        "    print(\"Dataset split complete.\")\n",
        "\n",
        "    # Initialize generators\n",
        "    batch_size = 32\n",
        "    train_generator = retrieve_generator(Train_set, image_path=image_path, batch_size=batch_size )\n",
        "    val_generator = retrieve_generator(Val_set, image_path=image_path, batch_size=batch_size)\n",
        "    test_generator = retrieve_generator(Test_set, image_path=image_path, batch_size=batch_size)\n",
        "\n",
        "    # Calculate steps per epoch\n",
        "    steps_per_epoch = len(Train_set) // batch_size\n",
        "    validation_steps = len(Val_set) // batch_size\n",
        "\n",
        "    # Create model\n",
        "    print(\"Creating model...\")\n",
        "    model = create_resnet_model()\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    history = train_resnet_model(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs=10)\n",
        "\n",
        "    # Fine-tune model\n",
        "    print(\"Fine-tuning model...\")\n",
        "    history_ft = fine_tune_resnet_model(model, train_generator, val_generator, steps_per_epoch, validation_steps)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"Evaluating model...\")\n",
        "    test_loss, test_accuracy = model.evaluate(test_generator, steps=len(Test_set) // batch_size)\n",
        "    print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    from google.colab import files\n",
        "\n",
        "    # Save the model to the current directory\n",
        "    model.save('deepfake_detector_resnet50.h5')\n",
        "\n",
        "    # Provide a link to download the model\n",
        "    files.download('deepfake_detector_resnet50.h5')\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.plot(history_ft.history['accuracy'], label='Fine-tuning Training Accuracy', linestyle='--')\n",
        "    plt.plot(history_ft.history['val_accuracy'], label='Fine-tuning Validation Accuracy', linestyle='--')\n",
        "    plt.title('Training and Fine-tuning Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.plot(history_ft.history['loss'], label='Fine-tuning Training Loss', linestyle='--')\n",
        "    plt.plot(history_ft.history['val_loss'], label='Fine-tuning Validation Loss', linestyle='--')\n",
        "    plt.title('Training and Fine-tuning Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AT7GELRhZHho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}